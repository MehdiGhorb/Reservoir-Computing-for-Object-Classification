{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN:\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9, alpha=0.99, density=0.5):\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Input weight matrix (including bias)\n",
    "        self.W_in = np.random.rand(reservoir_size, input_size + 1) - 0.5\n",
    "\n",
    "        # Reservoir weight matrix\n",
    "        self.W_res = np.zeros((reservoir_size, reservoir_size))\n",
    "        #max_edges = reservoir_size ** 2  # Maximum possible edges (for a graph, in which a node can also be connected to itself), otherwise d_max = n(n-1)/2\n",
    "        max_edges = reservoir_size * (reservoir_size - 1)\n",
    "        num_edges = int(density * max_edges)  # Number of edges based on density\n",
    "        indices = np.random.choice(max_edges, num_edges, replace=False) # Randomly assign `num_edges` connections\n",
    "        self.W_res.flat[indices] = np.random.rand(num_edges) - 0.5  # Random weights between -0.5 and 0.5\n",
    "\n",
    "        # Scale the reservoir weights to enforce spectral radius\n",
    "        self.W_res *= spectral_radius / np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "\n",
    "        # Output weight matrix\n",
    "        self.W_out = np.random.rand(output_size, reservoir_size) - 0.5\n",
    "\n",
    "        # Initial state\n",
    "        self.x0 = np.random.rand(reservoir_size)\n",
    "\n",
    "    def train(self, X_train, y_train, transient=100):\n",
    "        X_train = np.concatenate((np.ones((len(X_train), 1)), X_train), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_train), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_train)):\n",
    "            u = X_train[t]\n",
    "            x = self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, self.x0))\n",
    "            if t > transient:\n",
    "                X_res[t] = x\n",
    "\n",
    "        self.W_out = np.dot(np.linalg.pinv(X_res[transient:]), y_train[transient:])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.concatenate((np.ones((len(X_test), 1)), X_test), axis=1)  # Add bias term to input\n",
    "        X_res = np.zeros((len(X_test), self.reservoir_size))\n",
    "        x = np.zeros(self.reservoir_size)\n",
    "\n",
    "        for t in range(len(X_test)):\n",
    "            u = X_test[t]\n",
    "            x = self.alpha * np.tanh(np.dot(self.W_in, u) + np.dot(self.W_res, self.x0))\n",
    "            X_res[t] = x\n",
    "\n",
    "        return np.dot(X_res, self.W_out)\n",
    "\n",
    "    def identity(self, x):\n",
    "        return softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X = X / 255.0  # Normalize pixel values to range [0, 1]\n",
    "X = np.array(X)\n",
    "y = OneHotEncoder().fit_transform(y.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST classification using ESN with a network of 1000 neurons and alpha=1.0 and density=0.5\n",
    "alpha = 1.0\n",
    "reservoir_size = 1000\n",
    "density = 0.5\n",
    "output_size = 10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "esn = ESN(input_size, reservoir_size, output_size, alpha=alpha, density=density)\n",
    "esn.train(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "predictions = []\n",
    "for i in X_test:\n",
    "    predictions.append(esn.predict(i.reshape(1, -1)))\n",
    "\n",
    "predictions = np.array(predictions).reshape(-1, 10)\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
